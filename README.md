# gen_llm_api_server
生成式大语言模型API服务器

# 大语言模型API服务器使用指南
本文档介绍了如何使用基于阿里开发的Qwen1.5-0.5B大语言模型的API服务器。该服务器能够快速、准确地理解和回答您的问题，并通过API调用集成到您的应用程序中，提供智能问答服务。

## 项目源地址
- [Qwen1.5-0.5B-Chat](https://modelscope.cn/models/qwen/Qwen1.5-0.5B-Chat)

## 运行方式
根据是否需要上下文记忆对话的功能，选择以下任一方式运行服务器：
- python llm_api_server.py（不包含上下文记忆）
- python llm_api_server_history（包含上下文记忆）

**注意**：两者不能同时运行，否则会导致端口冲突。

## 服务器地址
大语言模型API服务器的默认地址为：`http://你的电脑IP:8088/`

## API接口详情
### 接口地址
```
/llm/
```

### 请求方式
- `GET`

### 请求参数
- `p`：必填，机器人角色设定。
- `q`：必填，用户提问内容。

## 使用示例
1. 在浏览器地址栏输入以下地址：
   ```
   http://127.0.0.1:8088/llm/?p=你是一个有用的助手&q=你好
   ```
2. 按下回车键，服务器将返回以下JSON格式的回答：
   ```json
   {
     "answer": "你好，有什么我可以帮助你的吗？"
   }
   ```

## 注意事项
1. API服务器仅支持`GET`请求方式。
2. 服务器返回的回答内容仅供参考，如有不准确之处，请以实际问答为准。
